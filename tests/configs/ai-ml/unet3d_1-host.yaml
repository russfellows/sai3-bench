# unet3d_gcs_test.yaml - 1 agent matching rdf-bench parameters
# GCS version of unet3d workload with nested directory structure
# 
# Matches rdf-bench config: width=28, depth=2, files=64 per host
# Size distribution matches: sizes=(1m,10,2m,20,4m,30,8m,25,16m,10,32m,5)
#
# rdf-bench equivalent: 1 host × 50,176 files = 50,176 files total
# Directory Structure:
#   width=28, depth=2 → 28 × 28 = 784 leaf directories
#   784 dirs × 64 files = 50,176 files per host
#   1 host × 50,176 = 50,176 total files
#
# Average file size: ~6.9 MB (weighted average from rdf-bench distribution)
# Total dataset: ~338 GB (1 host × 338 GB)

target: "gs://signal65-ai-ac/unet3d/"
duration: "5m"       # 300s run (matches rdf-bench rd_run elapsed=300)
concurrency: 32      # Matches rdf-bench threads=32

prepare:
  prepare_strategy: parallel
  skip_verification: true
  
  # Create nested directory tree matching rdf-bench FSD:
  # width=28, depth=2, files=64 (per host in rdf-bench)
  # rdf-bench: 1 host creates 784×64=50,176 files
  # sai3-bench: coordinator creates 1×50,176=50,176 files
  directory_structure:
    width: 28                # 28 subdirectories per level (matches rdf-bench)
    depth: 2                 # 2 levels deep (matches rdf-bench)
    files_per_dir: 64        # 64 files/host × 1 host = 64 files per directory
    distribution: "bottom"   # Files only in leaf directories
    dir_mask: "scan.d%d_w%d.dir"
  
  # Total files calculation: 784 leaf dirs × 64 files/dir = 50,176 files
  # This matches rdf-bench: 1 host × 50,176 files/host = 50,176 files
  ensure_objects:
    - base_uri: "gs://signal65-ai-ac/unet3d/"
      count: 50176  # 784 dirs × 64 files = 1 host × 50,176 files/host
      fill: random
      size_spec:
        type: lognormal
        mean: 7235174      # ~6.90 MB (matches rdf-bench weighted avg)
        std_dev: 5788139   # ~5.52 MB (provides spread similar to discrete dist)
        min: 1048576       # 1 MB minimum (matches rdf-bench)
        max: 33554432      # 32 MB maximum (matches rdf-bench)
      dedup_factor: 1
      compress_factor: 1
  
  cleanup: false  # Keep data between runs

workload:
  # Sequential reads matching rdf-bench:
  # operation=read, fileio=sequential, xfersize=1m
  # Each worker will select files uniformly at random
  
  - op: get
    path: "scan.d*_w*.dir/**/*"  # Match actual directory structure
    weight: 100

# Distributed Configuration (1 controller + 1 worker)
distributed:
  shared_filesystem: true  # GCS is shared across all agents
  tree_creation_mode: coordinator  # Controller creates directory tree once
  path_selection: random  # Random file selection for workload
  agents:
    - address: "10.138.0.42:7761"
      id: "agent-1"
