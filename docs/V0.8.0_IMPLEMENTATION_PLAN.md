# sai3-bench v0.8.0 Implementation Plan

**Target Release:** Q1 2026  
**Focus:** I/O Rate Control + Sequential Access Patterns  
**Estimated Effort:** 4-5 weeks total

---

## Executive Summary

Based on the v0.7.0 parity analysis, we're implementing the two highest-priority gaps:

1. **I/O Rate Control** (2-3 weeks) - Critical for production load simulation
2. **Sequential Access Patterns** (1-2 weeks) - High value, relatively straightforward

**NOT implementing:** Data validation/journaling (user decision - noted as deficiency)

---

## Phase 1: I/O Rate Control (Priority 1)

### Background: How rdf-bench Does It

From analyzing `rdf-bench` source code:

**Key Files:**
- `RD_entry.java` - Stores `iorate` parameter (line 54-56)
- `WG_entry.java` - Per-workload generator rate (`wg_iorate`)
- `WG_task.java` - Uses "waiter task" with inter-arrival time calculation
- Configuration: `iorate=1000` (1000 IOPS) or `iorate=max` (unlimited)

**Core Concept:**
- **Inter-arrival time** calculation: microseconds between I/O starts
  - `arrival = 1,000,000 / iorate_per_thread`
  - Example: `iorate=1000` with 10 threads → 100 µs between operations per thread
- **Distribution types:**
  - `distribution=0` - Exponential (default, realistic)
  - `distribution=1` - Uniform
  - `distribution=2` - Deterministic
- **Implementation:** Sleep/delay between operations to hit target rate
- **Special values:**
  - `iorate=max` (9999988) - Run at maximum throughput (no throttling)
  - `iorate=curve` - Dynamic rate adjustments over time

**Key Insight:** rdf-bench uses a centralized "waiter task" that schedules I/O start times across all workers, ensuring precise inter-arrival times even with variable operation latencies.

---

### sai3-bench Implementation Design

#### 1.1 Configuration Schema Changes

**File:** `src/config.rs`

Add to root `Config` struct:
```rust
/// Optional I/O rate control (v0.8.0+)
/// Controls the rate at which operations are issued (not completed)
#[serde(default)]
pub io_rate: Option<IoRateConfig>,
```

Add new configuration struct:
```rust
/// I/O rate control configuration (v0.8.0)
#[derive(Debug, Deserialize, Clone)]
pub struct IoRateConfig {
    /// Target operations per second (IOPS)
    /// Special values:
    /// - "max" or 0: No rate limiting (default behavior)
    /// - Numeric value: Target IOPS (e.g., 1000, 5000, 10000)
    #[serde(deserialize_with = "deserialize_iops")]
    pub iops: IopsTarget,
    
    /// Inter-arrival time distribution
    /// - exponential: Realistic Poisson arrival (default)
    /// - uniform: Fixed intervals
    /// - deterministic: Precise timing (testing only)
    #[serde(default = "default_distribution")]
    pub distribution: ArrivalDistribution,
    
    /// Optional per-operation rate overrides
    /// Allows different rates for GET vs PUT vs STAT, etc.
    #[serde(default)]
    pub per_operation: HashMap<String, u64>,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum IopsTarget {
    Max,              // Unlimited (no throttling)
    Fixed(u64),       // Fixed IOPS target
}

#[derive(Debug, Clone, Copy, PartialEq, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum ArrivalDistribution {
    Exponential,   // Poisson arrivals (realistic)
    Uniform,       // Fixed intervals
    Deterministic, // Precise timing
}

fn default_distribution() -> ArrivalDistribution {
    ArrivalDistribution::Exponential
}

fn deserialize_iops<'de, D>(deserializer: D) -> Result<IopsTarget, D::Error>
where
    D: serde::Deserializer<'de>,
{
    // Accept "max", 0, or positive integer
    // Implementation similar to duration parsing
}
```

**YAML Configuration Examples:**

```yaml
# Example 1: Simple fixed rate
duration: 60s
concurrency: 16
io_rate:
  iops: 1000  # 1000 total IOPS across all workers
workload:
  - weight: 70
    op: get
    path: "data/"
  - weight: 30
    op: put
    path: "data/"
    size_spec: { type: "fixed", value: 1048576 }

# Example 2: Unlimited (current behavior)
io_rate:
  iops: max  # Or just omit io_rate entirely

# Example 3: Advanced - per-operation rates
io_rate:
  iops: 2000
  distribution: exponential
  per_operation:
    get: 1500   # 1500 IOPS for GET
    put: 500    # 500 IOPS for PUT
    # STAT/DELETE/etc. share remaining capacity

# Example 4: Uniform distribution for synthetic testing
io_rate:
  iops: 5000
  distribution: uniform  # Precise fixed intervals
```

---

#### 1.2 Rate Controller Implementation

**New File:** `src/rate_controller.rs`

```rust
//! I/O rate control for workload execution (v0.8.0)
//! 
//! Implements inter-arrival time scheduling to control the rate at which
//! operations are issued (not their completion rate). Inspired by rdf-bench's
//! rate control mechanism but adapted for async Rust architecture.

use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Semaphore;
use tokio::time::sleep;
use rand::Rng;
use rand_distr::{Distribution, Exp};

use crate::config::{IoRateConfig, IopsTarget, ArrivalDistribution};

/// Rate controller for throttling operation starts
pub struct RateController {
    config: IoRateConfig,
    workers: usize,
    /// Per-worker target inter-arrival time (microseconds)
    inter_arrival_micros: f64,
    /// Exponential distribution generator (for realistic arrivals)
    exp_dist: Option<Exp<f64>>,
    /// Start time for rate tracking
    start_time: Instant,
    /// Operations issued so far
    ops_issued: Arc<std::sync::atomic::AtomicU64>,
}

impl RateController {
    pub fn new(config: IoRateConfig, workers: usize) -> Self {
        let inter_arrival_micros = match config.iops {
            IopsTarget::Max => 0.0,  // No throttling
            IopsTarget::Fixed(iops) => {
                // Inter-arrival time per worker
                // total_iops = workers * ops_per_worker_per_sec
                // inter_arrival = 1,000,000 / ops_per_worker_per_sec
                let ops_per_worker_per_sec = (iops as f64) / (workers as f64);
                1_000_000.0 / ops_per_worker_per_sec
            }
        };
        
        // Create exponential distribution if needed
        let exp_dist = if matches!(config.distribution, ArrivalDistribution::Exponential) 
                          && inter_arrival_micros > 0.0 {
            // Lambda = 1 / mean inter-arrival time
            Some(Exp::new(1.0 / inter_arrival_micros).unwrap())
        } else {
            None
        };
        
        Self {
            config,
            workers,
            inter_arrival_micros,
            exp_dist,
            start_time: Instant::now(),
            ops_issued: Arc::new(std::sync::atomic::AtomicU64::new(0)),
        }
    }
    
    /// Wait until next operation should be issued
    /// Returns immediately if no rate limiting is configured
    pub async fn wait_for_next(&self) {
        if self.inter_arrival_micros == 0.0 {
            return;  // No throttling
        }
        
        // Calculate delay based on distribution
        let delay_micros = match self.config.distribution {
            ArrivalDistribution::Exponential => {
                // Poisson arrivals (realistic)
                let mut rng = rand::thread_rng();
                self.exp_dist.as_ref().unwrap().sample(&mut rng)
            }
            ArrivalDistribution::Uniform => {
                // Fixed interval
                self.inter_arrival_micros
            }
            ArrivalDistribution::Deterministic => {
                // Precise timing - calculate exact delay to maintain rate
                let ops = self.ops_issued.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
                let target_time_micros = (ops as f64) * self.inter_arrival_micros;
                let elapsed_micros = self.start_time.elapsed().as_micros() as f64;
                let delay = target_time_micros - elapsed_micros;
                delay.max(0.0)  // Never negative
            }
        };
        
        if delay_micros > 0.0 {
            // Convert to Duration and sleep
            let delay = Duration::from_micros(delay_micros as u64);
            sleep(delay).await;
        }
    }
    
    /// Get current actual IOPS rate (for monitoring/debugging)
    pub fn current_rate(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed == 0.0 {
            return 0.0;
        }
        let ops = self.ops_issued.load(std::sync::atomic::Ordering::Relaxed);
        (ops as f64) / elapsed
    }
}

/// Wrapper for optional rate controller
/// Makes it easy to conditionally apply rate limiting
pub struct OptionalRateController {
    controller: Option<Arc<RateController>>,
}

impl OptionalRateController {
    pub fn new(config: Option<IoRateConfig>, workers: usize) -> Self {
        let controller = config.map(|cfg| Arc::new(RateController::new(cfg, workers)));
        Self { controller }
    }
    
    pub async fn wait(&self) {
        if let Some(ref ctrl) = self.controller {
            ctrl.wait_for_next().await;
        }
    }
    
    pub fn is_enabled(&self) -> bool {
        self.controller.is_some()
    }
}
```

---

#### 1.3 Integration into Workload Execution

**File:** `src/workload.rs`

**Changes to `run_workload()` function:**

1. **Create rate controller before spawning workers:**
```rust
// After parsing config and before worker spawn
let rate_controller = OptionalRateController::new(
    cfg.io_rate.clone(),
    cfg.concurrency
);

if rate_controller.is_enabled() {
    info!("I/O rate control enabled: {:?}", cfg.io_rate);
} else {
    info!("I/O rate control disabled - running at maximum throughput");
}
```

2. **Pass rate controller to each worker:**
```rust
let rate_ctrl_clone = rate_controller.clone();  // Arc clone

// In worker spawn loop
tokio::spawn(async move {
    // ... existing setup ...
    
    loop {
        // *** ADD: Wait for rate controller before selecting operation ***
        rate_ctrl_clone.wait().await;
        
        // Select operation
        let op_idx = chooser.sample(&mut r);
        
        // ... rest of operation execution ...
    }
});
```

**Key Implementation Points:**

- **Wait BEFORE operation selection** - Controls issue rate, not completion rate
- **Per-worker throttling** - Each worker independently throttles based on its share
- **Async-friendly** - Uses `tokio::time::sleep()` for efficient async waiting
- **Zero overhead when disabled** - `OptionalRateController` compiles to no-op

---

#### 1.4 Testing Strategy

**New Test Configs:**

```yaml
# tests/configs/rate-control/rate_1000_iops.yaml
duration: 30s
concurrency: 8
io_rate:
  iops: 1000
  distribution: exponential
target: "file:///tmp/sai3bench-rate-test"
prepare:
  objects: 100
  object_size: 1048576
workload:
  - weight: 100
    op: get
    path: "data/"

# tests/configs/rate-control/rate_5000_uniform.yaml
duration: 30s
concurrency: 16
io_rate:
  iops: 5000
  distribution: uniform
# ... rest same as above ...

# tests/configs/rate-control/rate_max.yaml
duration: 30s
concurrency: 16
io_rate:
  iops: max  # Should behave identically to omitting io_rate
# ... rest same ...
```

**Validation Tests:**

1. **Rate Accuracy Test:**
   - Run with `iops: 1000`, measure actual achieved IOPS
   - Tolerance: ±5% (950-1050 IOPS)

2. **Distribution Test:**
   - Exponential: Check inter-arrival times follow exponential distribution
   - Uniform: Check inter-arrival times are consistent
   - Use HDR histogram to validate distribution shape

3. **Multi-Concurrency Test:**
   - Test with concurrency: 1, 4, 8, 16, 32
   - Verify rate scales correctly across workers

4. **Performance Overhead Test:**
   - Compare `iops: max` vs no `io_rate` config
   - Overhead should be < 1% throughput impact

---

## Phase 2: Sequential Access Patterns (Priority 2)

### Background: How rdf-bench Does It

**Key Mechanisms:**

1. **`seekpct` parameter:**
   - `seekpct=100` - Pure random (default)
   - `seekpct=0` - Pure sequential
   - `seekpct=50` - 50% random, 50% sequential
   - `seekpct=-1` or `seekpct=eof` - Sequential until EOF, then restart

2. **Sequential tracking:**
   - `WG_context.next_seq` - Next sequential LBA
   - `WG_entry.wg_get_next_seq()` - Calculates next sequential position
   - Wraps around when reaching end of range

3. **Stride patterns:**
   - `stride=(min,max)` - Random offset added to sequential
   - Example: `stride=(4096,8192)` - Skip 4-8KB between operations
   - Used for skip-sequential patterns

**Code References:**
- `WG_entry.java:805-845` - `wg_get_next_seq()` implementation
- `WG_context.java:26` - `next_seq` tracking
- `WD_entry.java:48-53` - seekpct and stride configuration

---

### sai3-bench Implementation Design

#### 2.1 Configuration Schema Changes

**File:** `src/config.rs`

Add to `OpSpec::Get` and `OpSpec::Put`:
```rust
/// Access pattern configuration (v0.8.0+)
#[serde(default)]
pub access_pattern: Option<AccessPattern>,
```

Add new configuration struct:
```rust
/// Access pattern for file/object selection (v0.8.0)
#[derive(Debug, Deserialize, Clone)]
pub struct AccessPattern {
    /// Pattern type
    #[serde(rename = "type")]
    pub pattern_type: AccessPatternType,
    
    /// Optional stride for skip-sequential patterns
    #[serde(default)]
    pub stride: Option<StrideConfig>,
    
    /// Starting offset (bytes) for sequential patterns
    #[serde(default)]
    pub start_offset: u64,
}

#[derive(Debug, Clone, Copy, PartialEq, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum AccessPatternType {
    /// Pure random selection (default - current behavior)
    Random,
    
    /// Pure sequential - reads/writes files in order
    Sequential,
    
    /// Sequential until end, then wrap to beginning
    SequentialWrap,
    
    /// Mixed: percentage random vs sequential
    /// Format: "mixed:70" means 70% random, 30% sequential
    #[serde(untagged)]
    Mixed(u32),  // Percentage random (0-100)
}

#[derive(Debug, Deserialize, Clone)]
pub struct StrideConfig {
    /// Minimum stride offset (bytes)
    pub min: u64,
    /// Maximum stride offset (bytes)
    pub max: u64,
}
```

**YAML Configuration Examples:**

```yaml
# Example 1: Pure sequential reads
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: sequential
      start_offset: 0

# Example 2: Sequential with wraparound
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: sequential_wrap  # Restart from beginning at EOF

# Example 3: Skip-sequential (stride pattern)
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: sequential
      stride:
        min: 4096    # Skip 4KB minimum
        max: 8192    # Skip 8KB maximum

# Example 4: Mixed random/sequential (70% random, 30% sequential)
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: mixed
      random_pct: 70  # 70% random, 30% sequential

# Example 5: Directory tree with sequential file access
prepare:
  objects: 1000
  directory_structure:
    width: 3
    depth: 2
    files_per_dir: 10
    distribution: bottom
workload:
  - weight: 100
    op: get
    path: "tree/"
    access_pattern:
      type: sequential  # Read files sequentially through tree
```

---

#### 2.2 Sequential State Tracking

**New File:** `src/sequential_tracker.rs`

```rust
//! Sequential access pattern tracking (v0.8.0)
//! 
//! Maintains per-worker state for sequential file/object access patterns.
//! Inspired by rdf-bench's WG_context.next_seq tracking.

use std::sync::{Arc, Mutex};
use crate::config::{AccessPattern, AccessPatternType, StrideConfig};
use crate::directory_tree::PathSelector;

/// Tracks sequential position for a worker
pub struct SequentialTracker {
    /// Current position in file list
    position: Arc<Mutex<SequentialState>>,
    /// Access pattern configuration
    pattern: AccessPattern,
    /// Total number of files/objects available
    total_count: usize,
}

#[derive(Debug)]
struct SequentialState {
    /// Current index in file list
    current_index: usize,
    /// Current byte offset within file (for future range support)
    current_offset: u64,
    /// Total operations performed (for statistics)
    ops_count: u64,
}

impl SequentialTracker {
    pub fn new(pattern: AccessPattern, total_count: usize) -> Self {
        Self {
            position: Arc::new(Mutex::new(SequentialState {
                current_index: 0,
                current_offset: pattern.start_offset,
                ops_count: 0,
            })),
            pattern,
            total_count,
        }
    }
    
    /// Get next file index based on access pattern
    pub fn next_index(&self) -> usize {
        let mut state = self.position.lock().unwrap();
        state.ops_count += 1;
        
        match self.pattern.pattern_type {
            AccessPatternType::Random => {
                // Random selection (current behavior)
                rand::thread_rng().gen_range(0..self.total_count)
            }
            AccessPatternType::Sequential => {
                // Pure sequential
                let index = state.current_index;
                state.current_index = (state.current_index + 1) % self.total_count;
                
                // Apply stride if configured
                if let Some(ref stride) = self.pattern.stride {
                    let stride_amount = rand::thread_rng().gen_range(stride.min..=stride.max);
                    let stride_files = (stride_amount / AVG_FILE_SIZE) as usize;  // Approximate
                    state.current_index = (state.current_index + stride_files) % self.total_count;
                }
                
                index
            }
            AccessPatternType::SequentialWrap => {
                // Same as Sequential for now (wrapping is automatic with modulo)
                let index = state.current_index;
                state.current_index = (state.current_index + 1) % self.total_count;
                index
            }
            AccessPatternType::Mixed(random_pct) => {
                // Mixed: random_pct% random, (100-random_pct)% sequential
                let r: u32 = rand::thread_rng().gen_range(0..100);
                if r < random_pct {
                    // Random
                    rand::thread_rng().gen_range(0..self.total_count)
                } else {
                    // Sequential
                    let index = state.current_index;
                    state.current_index = (state.current_index + 1) % self.total_count;
                    index
                }
            }
        }
    }
    
    /// Get statistics (for reporting)
    pub fn stats(&self) -> SequentialStats {
        let state = self.position.lock().unwrap();
        SequentialStats {
            current_index: state.current_index,
            ops_count: state.ops_count,
            pattern_type: self.pattern.pattern_type,
        }
    }
}

#[derive(Debug)]
pub struct SequentialStats {
    pub current_index: usize,
    pub ops_count: u64,
    pub pattern_type: AccessPatternType,
}

const AVG_FILE_SIZE: u64 = 1048576;  // 1MB estimate for stride calculations
```

---

#### 2.3 Integration into PathSelector

**File:** `src/directory_tree.rs`

Modify `PathSelector` to support sequential access:

```rust
impl PathSelector {
    // ... existing methods ...
    
    /// Select file with sequential tracking (v0.8.0)
    pub fn select_file_with_pattern(&self, tracker: Option<&SequentialTracker>) -> String {
        if let Some(tracker) = tracker {
            // Sequential pattern - use tracker
            let index = tracker.next_index();
            self.get_file_by_index(index)
        } else {
            // Random pattern - use existing logic
            self.select_file()
        }
    }
    
    /// Get file by absolute index (v0.8.0 - for sequential access)
    fn get_file_by_index(&self, index: usize) -> String {
        let total_files = self.manifest.total_files;
        if total_files == 0 {
            panic!("No files in tree manifest");
        }
        
        // Wrap index if out of bounds
        let safe_index = index % total_files;
        
        // Traverse tree to find file at this index
        // This is the sequential equivalent of random file selection
        self.traverse_for_index(safe_index)
    }
    
    fn traverse_for_index(&self, target_index: usize) -> String {
        // Implementation: Walk directory tree maintaining running count
        // until we reach target_index
        // ... implementation details ...
    }
}
```

---

#### 2.4 Integration into Workload Execution

**File:** `src/workload.rs`

**Changes to worker execution loop:**

```rust
// Create sequential trackers if needed (before worker spawn)
let sequential_trackers: Vec<Option<Arc<SequentialTracker>>> = cfg.workload.iter()
    .map(|wo| {
        match &wo.spec {
            OpSpec::Get { access_pattern, .. } | 
            OpSpec::Put { access_pattern, .. } => {
                access_pattern.as_ref().map(|pattern| {
                    let total_count = if let Some(ref selector) = path_selector {
                        selector.total_files()
                    } else if let Some(ref pre) = prefetch_result {
                        // Count pre-resolved URIs
                        pre.get_lists.first().map(|l| l.full_uris.len()).unwrap_or(1000)
                    } else {
                        1000  // Default estimate
                    };
                    Arc::new(SequentialTracker::new(pattern.clone(), total_count))
                })
            }
            _ => None,
        }
    })
    .collect();

// In worker loop
let tracker_ref = sequential_trackers[op_idx].as_ref();

match &wo.spec {
    OpSpec::Get { path, .. } => {
        // Use PathSelector with sequential tracker
        let file_path = if let Some(ref selector) = path_selector {
            selector.select_file_with_pattern(tracker_ref.map(|t| t.as_ref()))
        } else {
            // Fallback to random selection
            // ... existing logic ...
        };
        
        // ... rest of GET operation ...
    }
    // ... similar for PUT ...
}
```

---

#### 2.5 Testing Strategy

**New Test Configs:**

```yaml
# tests/configs/sequential/seq_pure.yaml
duration: 30s
concurrency: 4
target: "file:///tmp/sai3bench-seq-test"
prepare:
  objects: 100
  object_size: 1048576
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: sequential

# tests/configs/sequential/seq_stride.yaml
duration: 30s
concurrency: 4
target: "file:///tmp/sai3bench-seq-test"
prepare:
  objects: 100
  object_size: 1048576
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: sequential
      stride:
        min: 4096
        max: 8192

# tests/configs/sequential/seq_mixed.yaml
duration: 30s
concurrency: 8
target: "file:///tmp/sai3bench-seq-test"
prepare:
  objects: 100
  object_size: 1048576
workload:
  - weight: 100
    op: get
    path: "data/"
    access_pattern:
      type: mixed
      random_pct: 70  # 70% random, 30% sequential
```

**Validation Tests:**

1. **Sequential Order Test:**
   - Enable debug logging to track file access order
   - Verify files accessed in sequential order (0, 1, 2, ...)
   - With 1 worker: Should be perfectly sequential

2. **Wraparound Test:**
   - Run with 100 files, 1000 operations
   - Verify position wraps to 0 after reaching 99

3. **Stride Test:**
   - Verify skip distances match configured stride range
   - Check distribution of skip distances

4. **Mixed Pattern Test:**
   - Run with `random_pct: 70`
   - Measure actual percentage of random vs sequential
   - Tolerance: ±5%

5. **Multi-Worker Sequential:**
   - Test with 4+ workers
   - Each worker should maintain independent sequential position
   - No collisions or duplicate accesses

---

## Phase 3: Documentation & Integration

### 3.1 User-Facing Documentation

**New/Updated Files:**

1. **`docs/IO_RATE_CONTROL_GUIDE.md`** (NEW - 20 pages)
   - What is I/O rate control and why it matters
   - Configuration examples (simple → advanced)
   - Distribution types explained
   - Per-operation rate overrides
   - Troubleshooting common issues
   - Performance characteristics
   - Comparison with rdf-bench `iorate=`

2. **`docs/SEQUENTIAL_ACCESS_GUIDE.md`** (NEW - 15 pages)
   - Access pattern types explained
   - Sequential vs random performance implications
   - Stride patterns for skip-sequential
   - Mixed patterns for realistic workloads
   - Directory tree sequential access
   - Comparison with rdf-bench `seekpct=`

3. **`docs/USER_GUIDE.md`** (UPDATE)
   - Add sections for I/O rate control
   - Add sections for access patterns
   - Update "Workload Configuration" chapter

4. **`README.md`** (UPDATE)
   - Mention I/O rate control in features list
   - Mention sequential patterns in features list

5. **`docs/CHANGELOG.md`** (UPDATE)
   - Document all v0.8.0 changes

---

### 3.2 Example Configurations

**New Directory:** `tests/configs/v0.8.0-features/`

Create 10+ example configs demonstrating:
- Simple rate limiting
- Advanced rate limiting with per-op overrides
- Sequential read/write patterns
- Mixed random/sequential workloads
- Stride patterns
- Rate control + sequential patterns combined
- Real-world scenarios (database simulation, streaming, etc.)

---

### 3.3 Update Comparison Document

**File:** `docs/V0.7.0_VS_RDF_BENCH_COMPARISON.md` → `docs/V0.8.0_VS_RDF_BENCH_COMPARISON.md`

Update parity matrix:

| Feature | rdf-bench | v0.7.0 | v0.8.0 | Change |
|---------|-----------|--------|--------|--------|
| **I/O rate control** | ✅ iorate= | ❌ Missing | ✅ io_rate | +100% |
| **Sequential access** | ✅ seekpct= | ❌ Missing | ✅ access_pattern | +100% |
| **Overall Parity** | 100% | 87% | **95%** | +8% |

---

## Implementation Timeline

### Week 1: I/O Rate Control - Configuration & Core (8-10 days)
- [ ] Day 1-2: Configuration schema (`config.rs`)
  - IoRateConfig struct
  - YAML deserialization
  - Input validation
  - Unit tests for config parsing
- [ ] Day 3-5: RateController implementation (`rate_controller.rs`)
  - Inter-arrival time calculations
  - Distribution implementations (exponential, uniform, deterministic)
  - Async sleep integration
  - Unit tests for rate calculations
- [ ] Day 6-8: Workload integration (`workload.rs`)
  - Integrate RateController into worker loop
  - Add rate limiting before operation selection
  - Per-operation rate overrides
  - Integration tests
- [ ] Day 9-10: Testing & validation
  - Accuracy tests (±5% tolerance)
  - Distribution tests
  - Performance overhead tests
  - Multi-concurrency tests

### Week 2: I/O Rate Control - Polish & Documentation (3-4 days)
- [ ] Day 11-12: Advanced features
  - Per-operation rate overrides
  - Rate monitoring/statistics
  - Error handling edge cases
- [ ] Day 13-14: Documentation
  - Write IO_RATE_CONTROL_GUIDE.md
  - Create 5+ example configs
  - Update USER_GUIDE.md
  - Update CHANGELOG.md

### Week 3: Sequential Access Patterns - Implementation (8-10 days)
- [ ] Day 15-16: Configuration schema
  - AccessPattern structs
  - YAML deserialization
  - Input validation
- [ ] Day 17-19: SequentialTracker implementation
  - State tracking per worker
  - Pattern implementations (sequential, mixed, stride)
  - Thread-safe state management
  - Unit tests
- [ ] Day 20-22: PathSelector integration
  - Add select_file_with_pattern()
  - Implement get_file_by_index()
  - Tree traversal for sequential access
- [ ] Day 23-24: Workload integration
  - Create sequential trackers
  - Pass to PathSelector
  - Integration tests

### Week 4: Sequential Access - Polish & Integration (5-7 days)
- [ ] Day 25-26: Testing & validation
  - Sequential order tests
  - Wraparound tests
  - Stride distribution tests
  - Mixed pattern tests
- [ ] Day 27-28: Documentation
  - Write SEQUENTIAL_ACCESS_GUIDE.md
  - Create 5+ example configs
  - Update USER_GUIDE.md
- [ ] Day 29-30: Final integration
  - Update parity comparison document
  - Create comprehensive v0.8.0 test matrix
  - Performance benchmarking
  - Update README.md

### Week 5: Release Preparation (3-5 days)
- [ ] Day 31-32: Comprehensive testing
  - Full test matrix execution
  - Azure/S3/GCS backend validation
  - Performance regression tests
  - Multi-platform testing (Linux, macOS)
- [ ] Day 33: Documentation review
  - Proofread all new docs
  - Verify example configs work
  - Check cross-references
- [ ] Day 34-35: Release
  - Update version numbers
  - Create RELEASE_v0.8.0.md
  - Tag release
  - Generate release notes

---

## Success Criteria

### I/O Rate Control (Phase 1)
- [ ] Rate accuracy within ±5% of target IOPS
- [ ] Zero performance overhead when disabled (`iops: max`)
- [ ] All distribution types working (exponential, uniform, deterministic)
- [ ] Per-operation rate overrides functional
- [ ] 10+ passing integration tests
- [ ] Comprehensive documentation (20+ pages)

### Sequential Access Patterns (Phase 2)
- [ ] Sequential order verified in single-worker tests
- [ ] Wraparound working correctly
- [ ] Stride patterns with correct distribution
- [ ] Mixed patterns achieve target random percentage (±5%)
- [ ] Multi-worker sequential state isolation working
- [ ] 10+ passing integration tests
- [ ] Comprehensive documentation (15+ pages)

### Overall v0.8.0 Release
- [ ] **95% parity with rdf-bench** (up from 87% in v0.7.0)
- [ ] All existing tests still passing (101 tests)
- [ ] 20+ new tests for v0.8.0 features
- [ ] Zero compiler warnings (continue v0.7.0 standard)
- [ ] Zero performance regression for existing workloads
- [ ] Complete documentation (50+ pages total)

---

## Risk Mitigation

### Risk 1: Rate Control Accuracy
**Risk:** Achieving ±5% accuracy across different backends and operation types  
**Mitigation:**
- Extensive testing with HDR histogram validation
- Measure inter-arrival times, not just completion rate
- Separate rate limiting from operation latency
- Test with fast (file://) and slow (s3://) backends

### Risk 2: Sequential Performance with Trees
**Risk:** Sequential tree traversal may be slow for large trees  
**Mitigation:**
- Build file index array during tree creation (O(1) access)
- Cache file paths for sequential iteration
- Profile and optimize if needed
- Document performance characteristics

### Risk 3: Multi-Worker Sequential Correctness
**Risk:** Workers may interfere with each other's sequential state  
**Mitigation:**
- Independent SequentialTracker per worker
- Thread-safe state with Mutex
- Comprehensive multi-worker tests
- Document expected behavior

### Risk 4: Configuration Complexity
**Risk:** Too many new configuration options may confuse users  
**Mitigation:**
- Sensible defaults (rate control disabled, random access)
- Clear documentation with examples
- Simple → advanced examples
- Backward compatibility (omitting new fields works)

---

## Notes from rdf-bench Code Analysis

### Key Learnings

1. **Rate control is about START time, not completion time**
   - rdf-bench schedules operation starts with precise inter-arrival times
   - Completion times vary based on storage latency
   - This is why it's called "iorate" not "throughput"

2. **Exponential distribution is default for a reason**
   - Mimics realistic Poisson arrival patterns
   - Uniform distribution is too synthetic
   - Deterministic is only for testing/debugging

3. **Sequential state must be per-worker**
   - Each worker maintains independent position
   - Prevents collisions and lock contention
   - Scales linearly with concurrency

4. **Stride patterns are underutilized but powerful**
   - Simulates real-world skip-sequential access
   - Database sequential scans with row size variation
   - Log file processing with varying record sizes

5. **Mixed patterns are more realistic than pure**
   - Most real workloads are mixed random/sequential
   - Pure patterns are edge cases
   - Example: 80% random metadata lookups + 20% sequential log writes

---

## Future Enhancements (Beyond v0.8.0)

These are NOT in scope for v0.8.0 but noted for future consideration:

### 1. Dynamic Rate Curves (v0.9.0?)
- rdf-bench's `iorate=curve` feature
- Ramp up/down over time
- Burst patterns
- Requires more complex scheduling

### 2. Hot-Banding (v0.9.0?)
- Concentrated access to specific LBA/file ranges
- rdf-bench's `range=(low,high)` feature
- Simulates working set behavior

### 3. Multi-Host Coordination (v0.9.0?)
- Coordinate sequential access across agents
- Prevent multiple agents from sequential overlap
- Requires gRPC coordination protocol

### 4. Cache Hit Simulation (v1.0.0?)
- rdf-bench's `rhpct=` and `whpct=` features
- Simulate cache hit ratios
- Requires read-after-write tracking

---

## Appendix: Configuration Reference

### Complete v0.8.0 Configuration Example

```yaml
# Comprehensive v0.8.0 workload configuration
# Demonstrates all new features

duration: 300s  # 5 minutes
concurrency: 16

# NEW: I/O rate control (v0.8.0)
io_rate:
  iops: 5000                    # Target 5000 total IOPS
  distribution: exponential     # Realistic Poisson arrivals
  per_operation:
    get: 4000                   # 4000 IOPS for reads
    put: 1000                   # 1000 IOPS for writes

target: "s3://my-bucket/test/"

prepare:
  objects: 10000
  directory_structure:
    width: 5
    depth: 3
    files_per_dir: 20
    distribution: all
  tree_creation: coordinator

workload:
  # Sequential read workload (70% weight)
  - weight: 70
    op: get
    path: "tree/"
    access_pattern:
      type: sequential_wrap     # NEW: Sequential with wraparound (v0.8.0)
      start_offset: 0
    
  # Random write workload (20% weight)
  - weight: 20
    op: put
    path: "tree/"
    size_spec:
      type: lognormal
      mean: 1048576
      stdev: 524288
    access_pattern:
      type: random              # Random file selection (default)
    
  # Skip-sequential metadata operations (10% weight)
  - weight: 10
    op: stat
    path: "tree/"
    access_pattern:
      type: sequential          # NEW: Sequential with stride (v0.8.0)
      stride:
        min: 8192
        max: 16384

# Optional: RangeEngine for S3 performance
range_engine:
  enabled: true
  chunk_size: 5242880
  max_concurrent_ranges: 8
```

---

**Document Version:** 1.0  
**Author:** sai3-bench development team  
**Last Updated:** October 31, 2025  
**Target Completion:** Q1 2026
