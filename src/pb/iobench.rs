// This file is @generated by prost-build.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct Empty {}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PingReply {
    #[prost(string, tag = "1")]
    pub version: ::prost::alloc::string::String,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RunGetRequest {
    /// "s3://bucket/prefix/*" or "s3://bucket/prefix/"
    #[prost(string, tag = "1")]
    pub uri: ::prost::alloc::string::String,
    /// concurrency per-agent
    #[prost(uint32, tag = "2")]
    pub jobs: u32,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RunPutRequest {
    #[prost(string, tag = "1")]
    pub bucket: ::prost::alloc::string::String,
    /// "bench/"
    #[prost(string, tag = "2")]
    pub prefix: ::prost::alloc::string::String,
    /// bytes
    #[prost(uint64, tag = "3")]
    pub object_size: u64,
    /// number of objects
    #[prost(uint32, tag = "4")]
    pub objects: u32,
    /// per-agent parallel uploads
    #[prost(uint32, tag = "5")]
    pub concurrency: u32,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct OpSummary {
    #[prost(uint64, tag = "1")]
    pub total_bytes: u64,
    #[prost(double, tag = "2")]
    pub seconds: f64,
    #[prost(string, tag = "3")]
    pub notes: ::prost::alloc::string::String,
}
/// v0.6.0: Distributed workload execution
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RunWorkloadRequest {
    /// Full YAML configuration as string
    #[prost(string, tag = "1")]
    pub config_yaml: ::prost::alloc::string::String,
    /// Unique agent identifier (e.g., "agent-1")
    #[prost(string, tag = "2")]
    pub agent_id: ::prost::alloc::string::String,
    /// Per-agent path isolation prefix (e.g., "agent-1/")
    #[prost(string, tag = "3")]
    pub path_prefix: ::prost::alloc::string::String,
    /// Coordinated start time (nanoseconds since UNIX epoch)
    #[prost(int64, tag = "4")]
    pub start_timestamp_ns: i64,
    /// True if storage is shared (S3/GCS/Azure), false if local per-agent
    #[prost(bool, tag = "5")]
    pub shared_storage: bool,
}
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct OpAggregateMetrics {
    #[prost(uint64, tag = "1")]
    pub bytes: u64,
    #[prost(uint64, tag = "2")]
    pub ops: u64,
    #[prost(uint64, tag = "3")]
    pub mean_us: u64,
    #[prost(uint64, tag = "4")]
    pub p50_us: u64,
    #[prost(uint64, tag = "5")]
    pub p95_us: u64,
    #[prost(uint64, tag = "6")]
    pub p99_us: u64,
}
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct WorkloadSummary {
    #[prost(string, tag = "1")]
    pub agent_id: ::prost::alloc::string::String,
    #[prost(double, tag = "2")]
    pub wall_seconds: f64,
    #[prost(uint64, tag = "3")]
    pub total_ops: u64,
    #[prost(uint64, tag = "4")]
    pub total_bytes: u64,
    /// Per-operation aggregates
    #[prost(message, optional, tag = "5")]
    pub get: ::core::option::Option<OpAggregateMetrics>,
    #[prost(message, optional, tag = "6")]
    pub put: ::core::option::Option<OpAggregateMetrics>,
    #[prost(message, optional, tag = "7")]
    pub meta: ::core::option::Option<OpAggregateMetrics>,
    /// Overall percentiles (from combined histogram)
    #[prost(uint64, tag = "8")]
    pub p50_us: u64,
    #[prost(uint64, tag = "9")]
    pub p95_us: u64,
    #[prost(uint64, tag = "10")]
    pub p99_us: u64,
    /// v0.6.4: Agent results collection (inline for small results)
    ///
    /// Agent console output
    #[prost(string, tag = "11")]
    pub console_log: ::prost::alloc::string::String,
    /// Agent metadata JSON
    #[prost(string, tag = "12")]
    pub metadata_json: ::prost::alloc::string::String,
    /// TSV results data
    #[prost(string, tag = "13")]
    pub tsv_content: ::prost::alloc::string::String,
    /// Local path where agent saved results
    #[prost(string, tag = "14")]
    pub results_path: ::prost::alloc::string::String,
    /// Optional: path to operation log (not transferred)
    #[prost(string, tag = "15")]
    pub op_log_path: ::prost::alloc::string::String,
    /// v0.6.4: HDR histogram data for accurate aggregation
    ///
    /// Serialized GET histograms (all size buckets)
    #[prost(bytes = "vec", tag = "16")]
    pub histogram_get: ::prost::alloc::vec::Vec<u8>,
    /// Serialized PUT histograms (all size buckets)
    #[prost(bytes = "vec", tag = "17")]
    pub histogram_put: ::prost::alloc::vec::Vec<u8>,
    /// Serialized META histograms (all size buckets)
    #[prost(bytes = "vec", tag = "18")]
    pub histogram_meta: ::prost::alloc::vec::Vec<u8>,
}
/// v0.7.9: Prepare phase summary (similar to WorkloadSummary but for object creation)
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PrepareSummary {
    #[prost(string, tag = "1")]
    pub agent_id: ::prost::alloc::string::String,
    #[prost(double, tag = "2")]
    pub wall_seconds: f64,
    #[prost(uint64, tag = "3")]
    pub objects_created: u64,
    #[prost(uint64, tag = "4")]
    pub objects_existed: u64,
    /// PUT operation aggregates (object creation)
    #[prost(message, optional, tag = "5")]
    pub put: ::core::option::Option<OpAggregateMetrics>,
    /// MKDIR operation aggregates (directory creation)
    #[prost(message, optional, tag = "6")]
    pub mkdir: ::core::option::Option<OpAggregateMetrics>,
    #[prost(uint64, tag = "7")]
    pub mkdir_count: u64,
    /// v0.7.9: HDR histogram data for accurate aggregation
    ///
    /// Serialized PUT histograms (all size buckets)
    #[prost(bytes = "vec", tag = "8")]
    pub histogram_put: ::prost::alloc::vec::Vec<u8>,
    /// v0.7.9: TSV content for agent-level prepare results
    ///
    /// Prepare results TSV data
    #[prost(string, tag = "9")]
    pub tsv_content: ::prost::alloc::string::String,
    /// Local path where agent saved prepare_results.tsv
    #[prost(string, tag = "10")]
    pub results_path: ::prost::alloc::string::String,
}
/// v0.7.5: Live performance statistics for distributed execution
/// Sent every 1 second during workload execution for real-time visibility
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LiveStats {
    #[prost(string, tag = "1")]
    pub agent_id: ::prost::alloc::string::String,
    /// Seconds since workload start
    #[prost(double, tag = "2")]
    pub timestamp_s: f64,
    /// GET operations (read from storage)
    #[prost(uint64, tag = "3")]
    pub get_ops: u64,
    #[prost(uint64, tag = "4")]
    pub get_bytes: u64,
    #[prost(double, tag = "5")]
    pub get_mean_us: f64,
    #[prost(double, tag = "6")]
    pub get_p50_us: f64,
    #[prost(double, tag = "7")]
    pub get_p95_us: f64,
    /// PUT operations (write to storage)
    #[prost(uint64, tag = "8")]
    pub put_ops: u64,
    #[prost(uint64, tag = "9")]
    pub put_bytes: u64,
    #[prost(double, tag = "10")]
    pub put_mean_us: f64,
    #[prost(double, tag = "11")]
    pub put_p50_us: f64,
    #[prost(double, tag = "12")]
    pub put_p95_us: f64,
    /// META operations (LIST/HEAD/DELETE/etc.)
    #[prost(uint64, tag = "13")]
    pub meta_ops: u64,
    #[prost(double, tag = "14")]
    pub meta_mean_us: f64,
    #[prost(double, tag = "15")]
    pub elapsed_s: f64,
    /// True on final message
    #[prost(bool, tag = "16")]
    pub completed: bool,
    /// v0.7.5: Optional final summary (only present when completed=true)
    /// Allows controller to collect complete results for persistence
    #[prost(message, optional, tag = "17")]
    pub final_summary: ::core::option::Option<WorkloadSummary>,
    #[prost(enumeration = "live_stats::Status", tag = "18")]
    pub status: i32,
    /// Details if status == ERROR
    #[prost(string, tag = "19")]
    pub error_message: ::prost::alloc::string::String,
    /// v0.7.9: Prepare phase progress tracking
    ///
    /// True if currently in prepare phase
    #[prost(bool, tag = "20")]
    pub in_prepare_phase: bool,
    /// Objects created so far
    #[prost(uint64, tag = "21")]
    pub prepare_objects_created: u64,
    /// Total objects to create
    #[prost(uint64, tag = "22")]
    pub prepare_objects_total: u64,
    /// v0.7.9: Prepare phase summary (only present when prepare completes)
    #[prost(message, optional, tag = "23")]
    pub prepare_summary: ::core::option::Option<PrepareSummary>,
    /// v0.7.11: CPU utilization metrics (sampled every 5 seconds)
    ///
    /// User mode CPU utilization (0-100%)
    #[prost(double, tag = "24")]
    pub cpu_user_percent: f64,
    /// System/kernel mode CPU utilization (0-100%)
    #[prost(double, tag = "25")]
    pub cpu_system_percent: f64,
    /// IO-wait CPU time (0-100%)
    #[prost(double, tag = "26")]
    pub cpu_iowait_percent: f64,
    /// Total CPU utilization (user+system+iowait)
    #[prost(double, tag = "27")]
    pub cpu_total_percent: f64,
    /// v0.8.4: Clock synchronization for coordinated start
    /// When status=READY, agent includes its current timestamp
    /// Controller calculates offset and adjusts start_timestamp_ns accordingly
    ///
    /// Agent's system time (nanoseconds since UNIX epoch)
    #[prost(int64, tag = "28")]
    pub agent_timestamp_ns: i64,
    /// v0.8.4: Sequence number for message tracking and acknowledgment
    /// Allows controller to confirm receipt of specific messages (e.g., READY status)
    #[prost(int64, tag = "29")]
    pub sequence: i64,
}
/// Nested message and enum types in `LiveStats`.
pub mod live_stats {
    /// v0.7.6: Startup handshake for robust error handling
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Status {
        Unknown = 0,
        /// Agent validated config and is ready to start
        Ready = 1,
        /// Workload is executing (normal stats messages)
        Running = 2,
        /// Agent encountered startup error (see error_message)
        Error = 3,
        /// Workload finished successfully
        Completed = 4,
    }
    impl Status {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unknown => "UNKNOWN",
                Self::Ready => "READY",
                Self::Running => "RUNNING",
                Self::Error => "ERROR",
                Self::Completed => "COMPLETED",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "UNKNOWN" => Some(Self::Unknown),
                "READY" => Some(Self::Ready),
                "RUNNING" => Some(Self::Running),
                "ERROR" => Some(Self::Error),
                "COMPLETED" => Some(Self::Completed),
                _ => None,
            }
        }
    }
}
/// v0.8.4: Control messages from controller to agent
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ControlMessage {
    #[prost(enumeration = "control_message::Command", tag = "1")]
    pub command: i32,
    /// For START command: workload configuration
    #[prost(string, tag = "2")]
    pub config_yaml: ::prost::alloc::string::String,
    #[prost(string, tag = "3")]
    pub agent_id: ::prost::alloc::string::String,
    #[prost(string, tag = "4")]
    pub path_prefix: ::prost::alloc::string::String,
    #[prost(int64, tag = "5")]
    pub start_timestamp_ns: i64,
    #[prost(bool, tag = "6")]
    pub shared_storage: bool,
    /// For ACKNOWLEDGE: which message we're acknowledging
    #[prost(int64, tag = "7")]
    pub ack_sequence: i64,
}
/// Nested message and enum types in `ControlMessage`.
pub mod control_message {
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Command {
        /// Keepalive / connection check
        Ping = 0,
        /// Begin workload execution
        Start = 1,
        /// Cancel workload immediately
        Abort = 2,
        /// Acknowledge receipt of agent message
        Acknowledge = 3,
    }
    impl Command {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Ping => "PING",
                Self::Start => "START",
                Self::Abort => "ABORT",
                Self::Acknowledge => "ACKNOWLEDGE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "PING" => Some(Self::Ping),
                "START" => Some(Self::Start),
                "ABORT" => Some(Self::Abort),
                "ACKNOWLEDGE" => Some(Self::Acknowledge),
                _ => None,
            }
        }
    }
}
/// Generated client implementations.
pub mod agent_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct AgentClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl AgentClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> AgentClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> AgentClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            AgentClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        pub async fn ping(
            &mut self,
            request: impl tonic::IntoRequest<super::Empty>,
        ) -> std::result::Result<tonic::Response<super::PingReply>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/iobench.Agent/Ping");
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("iobench.Agent", "Ping"));
            self.inner.unary(req, path, codec).await
        }
        pub async fn run_get(
            &mut self,
            request: impl tonic::IntoRequest<super::RunGetRequest>,
        ) -> std::result::Result<tonic::Response<super::OpSummary>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/iobench.Agent/RunGet");
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("iobench.Agent", "RunGet"));
            self.inner.unary(req, path, codec).await
        }
        pub async fn run_put(
            &mut self,
            request: impl tonic::IntoRequest<super::RunPutRequest>,
        ) -> std::result::Result<tonic::Response<super::OpSummary>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/iobench.Agent/RunPut");
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("iobench.Agent", "RunPut"));
            self.inner.unary(req, path, codec).await
        }
        pub async fn run_workload(
            &mut self,
            request: impl tonic::IntoRequest<super::RunWorkloadRequest>,
        ) -> std::result::Result<
            tonic::Response<super::WorkloadSummary>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/iobench.Agent/RunWorkload",
            );
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("iobench.Agent", "RunWorkload"));
            self.inner.unary(req, path, codec).await
        }
        /// v0.7.5: Server streaming for live progress updates during distributed execution
        pub async fn run_workload_with_live_stats(
            &mut self,
            request: impl tonic::IntoRequest<super::RunWorkloadRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::LiveStats>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/iobench.Agent/RunWorkloadWithLiveStats",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("iobench.Agent", "RunWorkloadWithLiveStats"));
            self.inner.server_streaming(req, path, codec).await
        }
        /// v0.7.11: Abort ongoing workload (controller failure, user interrupt, etc.)
        pub async fn abort_workload(
            &mut self,
            request: impl tonic::IntoRequest<super::Empty>,
        ) -> std::result::Result<tonic::Response<super::Empty>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/iobench.Agent/AbortWorkload",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("iobench.Agent", "AbortWorkload"));
            self.inner.unary(req, path, codec).await
        }
        /// v0.8.4: Bidirectional streaming for robust control and stats
        /// Controller sends control messages (start, abort, ping)
        /// Agent sends stats updates (ready, progress, completed)
        /// Allows real-time coordination without blocking either side
        pub async fn execute_workload(
            &mut self,
            request: impl tonic::IntoStreamingRequest<Message = super::ControlMessage>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::LiveStats>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/iobench.Agent/ExecuteWorkload",
            );
            let mut req = request.into_streaming_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("iobench.Agent", "ExecuteWorkload"));
            self.inner.streaming(req, path, codec).await
        }
    }
}
/// Generated server implementations.
pub mod agent_server {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    /// Generated trait containing gRPC methods that should be implemented for use with AgentServer.
    #[async_trait]
    pub trait Agent: std::marker::Send + std::marker::Sync + 'static {
        async fn ping(
            &self,
            request: tonic::Request<super::Empty>,
        ) -> std::result::Result<tonic::Response<super::PingReply>, tonic::Status>;
        async fn run_get(
            &self,
            request: tonic::Request<super::RunGetRequest>,
        ) -> std::result::Result<tonic::Response<super::OpSummary>, tonic::Status>;
        async fn run_put(
            &self,
            request: tonic::Request<super::RunPutRequest>,
        ) -> std::result::Result<tonic::Response<super::OpSummary>, tonic::Status>;
        async fn run_workload(
            &self,
            request: tonic::Request<super::RunWorkloadRequest>,
        ) -> std::result::Result<tonic::Response<super::WorkloadSummary>, tonic::Status>;
        /// Server streaming response type for the RunWorkloadWithLiveStats method.
        type RunWorkloadWithLiveStatsStream: tonic::codegen::tokio_stream::Stream<
                Item = std::result::Result<super::LiveStats, tonic::Status>,
            >
            + std::marker::Send
            + 'static;
        /// v0.7.5: Server streaming for live progress updates during distributed execution
        async fn run_workload_with_live_stats(
            &self,
            request: tonic::Request<super::RunWorkloadRequest>,
        ) -> std::result::Result<
            tonic::Response<Self::RunWorkloadWithLiveStatsStream>,
            tonic::Status,
        >;
        /// v0.7.11: Abort ongoing workload (controller failure, user interrupt, etc.)
        async fn abort_workload(
            &self,
            request: tonic::Request<super::Empty>,
        ) -> std::result::Result<tonic::Response<super::Empty>, tonic::Status>;
        /// Server streaming response type for the ExecuteWorkload method.
        type ExecuteWorkloadStream: tonic::codegen::tokio_stream::Stream<
                Item = std::result::Result<super::LiveStats, tonic::Status>,
            >
            + std::marker::Send
            + 'static;
        /// v0.8.4: Bidirectional streaming for robust control and stats
        /// Controller sends control messages (start, abort, ping)
        /// Agent sends stats updates (ready, progress, completed)
        /// Allows real-time coordination without blocking either side
        async fn execute_workload(
            &self,
            request: tonic::Request<tonic::Streaming<super::ControlMessage>>,
        ) -> std::result::Result<
            tonic::Response<Self::ExecuteWorkloadStream>,
            tonic::Status,
        >;
    }
    #[derive(Debug)]
    pub struct AgentServer<T> {
        inner: Arc<T>,
        accept_compression_encodings: EnabledCompressionEncodings,
        send_compression_encodings: EnabledCompressionEncodings,
        max_decoding_message_size: Option<usize>,
        max_encoding_message_size: Option<usize>,
    }
    impl<T> AgentServer<T> {
        pub fn new(inner: T) -> Self {
            Self::from_arc(Arc::new(inner))
        }
        pub fn from_arc(inner: Arc<T>) -> Self {
            Self {
                inner,
                accept_compression_encodings: Default::default(),
                send_compression_encodings: Default::default(),
                max_decoding_message_size: None,
                max_encoding_message_size: None,
            }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> InterceptedService<Self, F>
        where
            F: tonic::service::Interceptor,
        {
            InterceptedService::new(Self::new(inner), interceptor)
        }
        /// Enable decompressing requests with the given encoding.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.accept_compression_encodings.enable(encoding);
            self
        }
        /// Compress responses with the given encoding, if the client supports it.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.send_compression_encodings.enable(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.max_decoding_message_size = Some(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.max_encoding_message_size = Some(limit);
            self
        }
    }
    impl<T, B> tonic::codegen::Service<http::Request<B>> for AgentServer<T>
    where
        T: Agent,
        B: Body + std::marker::Send + 'static,
        B::Error: Into<StdError> + std::marker::Send + 'static,
    {
        type Response = http::Response<tonic::body::Body>;
        type Error = std::convert::Infallible;
        type Future = BoxFuture<Self::Response, Self::Error>;
        fn poll_ready(
            &mut self,
            _cx: &mut Context<'_>,
        ) -> Poll<std::result::Result<(), Self::Error>> {
            Poll::Ready(Ok(()))
        }
        fn call(&mut self, req: http::Request<B>) -> Self::Future {
            match req.uri().path() {
                "/iobench.Agent/Ping" => {
                    #[allow(non_camel_case_types)]
                    struct PingSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::UnaryService<super::Empty>
                    for PingSvc<T> {
                        type Response = super::PingReply;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::Empty>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::ping(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = PingSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/RunGet" => {
                    #[allow(non_camel_case_types)]
                    struct RunGetSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::UnaryService<super::RunGetRequest>
                    for RunGetSvc<T> {
                        type Response = super::OpSummary;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::RunGetRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::run_get(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = RunGetSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/RunPut" => {
                    #[allow(non_camel_case_types)]
                    struct RunPutSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::UnaryService<super::RunPutRequest>
                    for RunPutSvc<T> {
                        type Response = super::OpSummary;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::RunPutRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::run_put(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = RunPutSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/RunWorkload" => {
                    #[allow(non_camel_case_types)]
                    struct RunWorkloadSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::UnaryService<super::RunWorkloadRequest>
                    for RunWorkloadSvc<T> {
                        type Response = super::WorkloadSummary;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::RunWorkloadRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::run_workload(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = RunWorkloadSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/RunWorkloadWithLiveStats" => {
                    #[allow(non_camel_case_types)]
                    struct RunWorkloadWithLiveStatsSvc<T: Agent>(pub Arc<T>);
                    impl<
                        T: Agent,
                    > tonic::server::ServerStreamingService<super::RunWorkloadRequest>
                    for RunWorkloadWithLiveStatsSvc<T> {
                        type Response = super::LiveStats;
                        type ResponseStream = T::RunWorkloadWithLiveStatsStream;
                        type Future = BoxFuture<
                            tonic::Response<Self::ResponseStream>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::RunWorkloadRequest>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::run_workload_with_live_stats(&inner, request)
                                    .await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = RunWorkloadWithLiveStatsSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.server_streaming(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/AbortWorkload" => {
                    #[allow(non_camel_case_types)]
                    struct AbortWorkloadSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::UnaryService<super::Empty>
                    for AbortWorkloadSvc<T> {
                        type Response = super::Empty;
                        type Future = BoxFuture<
                            tonic::Response<Self::Response>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<super::Empty>,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::abort_workload(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = AbortWorkloadSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.unary(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                "/iobench.Agent/ExecuteWorkload" => {
                    #[allow(non_camel_case_types)]
                    struct ExecuteWorkloadSvc<T: Agent>(pub Arc<T>);
                    impl<T: Agent> tonic::server::StreamingService<super::ControlMessage>
                    for ExecuteWorkloadSvc<T> {
                        type Response = super::LiveStats;
                        type ResponseStream = T::ExecuteWorkloadStream;
                        type Future = BoxFuture<
                            tonic::Response<Self::ResponseStream>,
                            tonic::Status,
                        >;
                        fn call(
                            &mut self,
                            request: tonic::Request<
                                tonic::Streaming<super::ControlMessage>,
                            >,
                        ) -> Self::Future {
                            let inner = Arc::clone(&self.0);
                            let fut = async move {
                                <T as Agent>::execute_workload(&inner, request).await
                            };
                            Box::pin(fut)
                        }
                    }
                    let accept_compression_encodings = self.accept_compression_encodings;
                    let send_compression_encodings = self.send_compression_encodings;
                    let max_decoding_message_size = self.max_decoding_message_size;
                    let max_encoding_message_size = self.max_encoding_message_size;
                    let inner = self.inner.clone();
                    let fut = async move {
                        let method = ExecuteWorkloadSvc(inner);
                        let codec = tonic::codec::ProstCodec::default();
                        let mut grpc = tonic::server::Grpc::new(codec)
                            .apply_compression_config(
                                accept_compression_encodings,
                                send_compression_encodings,
                            )
                            .apply_max_message_size_config(
                                max_decoding_message_size,
                                max_encoding_message_size,
                            );
                        let res = grpc.streaming(method, req).await;
                        Ok(res)
                    };
                    Box::pin(fut)
                }
                _ => {
                    Box::pin(async move {
                        let mut response = http::Response::new(
                            tonic::body::Body::default(),
                        );
                        let headers = response.headers_mut();
                        headers
                            .insert(
                                tonic::Status::GRPC_STATUS,
                                (tonic::Code::Unimplemented as i32).into(),
                            );
                        headers
                            .insert(
                                http::header::CONTENT_TYPE,
                                tonic::metadata::GRPC_CONTENT_TYPE,
                            );
                        Ok(response)
                    })
                }
            }
        }
    }
    impl<T> Clone for AgentServer<T> {
        fn clone(&self) -> Self {
            let inner = self.inner.clone();
            Self {
                inner,
                accept_compression_encodings: self.accept_compression_encodings,
                send_compression_encodings: self.send_compression_encodings,
                max_decoding_message_size: self.max_decoding_message_size,
                max_encoding_message_size: self.max_encoding_message_size,
            }
        }
    }
    /// Generated gRPC service name
    pub const SERVICE_NAME: &str = "iobench.Agent";
    impl<T> tonic::server::NamedService for AgentServer<T> {
        const NAME: &'static str = SERVICE_NAME;
    }
}
